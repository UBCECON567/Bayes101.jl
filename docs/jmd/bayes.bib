@article{chernozhukov2003,
title = "An \{MCMC\} approach to classical estimation ",
journal = "Journal of Econometrics ",
volume = "115",
number = "2",
pages = "293 - 346",
year = "2003",
note = "",
issn = "0304-4076",
doi = "http://dx.doi.org/10.1016/S0304-4076(03)00100-3",
url = "http://www.sciencedirect.com/science/article/pii/S0304407603001003",
author = "Victor Chernozhukov and Han Hong",
keywords = "Laplace",
keywords = "Bayes",
keywords = "Markov Chain Monte Carlo",
keywords = "\{GMM\}",
keywords = "Instrumental regression",
keywords = "Censored quantile regression",
keywords = "Instrumental quantile regression",
keywords = "Empirical likelihood",
keywords = "Value-at-risk ",
abstract = "This paper studies computationally and theoretically attractive estimators called here Laplace type estimators (LTEs), which include means and quantiles of quasi-posterior distributions defined as transformations of general (nonlikelihood-based) statistical criterion functions, such as those in GMM, nonlinear IV, empirical likelihood, and minimum distance methods. The approach generates an alternative to classical extremum estimation and also falls outside the parametric Bayesian approach. For example, it offers a new attractive estimation method for such important semi-parametric problems as censored and instrumental quantile regression, nonlinear \{GMM\} and value-at-risk models. The \{LTEs\} are computed using Markov Chain Monte Carlo methods, which help circumvent the computational curse of dimensionality. A large sample theory is obtained and illustrated for regular cases. "
}

@article{jiang2009,
  title={Bayesian analysis of random coefficient logit models using aggregate data},
  author={Jiang, R. and Manchanda, P. and Rossi, P.E.},
  journal={Journal of Econometrics},
  volume={149},
  number={2},
  pages={136--148},
  year={2009},
  url={http://www.sciencedirect.com/science/article/pii/S0304407608002297},
  publisher={Elsevier}
}

@article{weave,
 author={Pastell, Matti},
 year={2017},
 title={Weave.jl: Scientific Reports Using Julia.},
 journal={The Journal of Open Source Software},
 doi={http://dx.doi.org/10.21105/joss.00204},
 url={https://github.com/JunoLab/Weave.jl}
 }

@article{hoffman2014,
  title={The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo.},
    author={Hoffman, Matthew D and Gelman, Andrew},
      journal={Journal of Machine Learning Research},
        volume={15},
          number={1},
            pages={1593--1623},
              year={2014},
              url={http://www.jmlr.org/papers/volume15/hoffman14a/hoffman14a.pdf}
              }


@article{chung2015,
author = {Yeojin Chung and Andrew Gelman and Sophia Rabe-Hesketh and Jingchen Liu and Vincent Dorie},
title ={Weakly Informative Prior for Point Estimation of Covariance Matrices in Hierarchical Models},
journal = {Journal of Educational and Behavioral Statistics},
volume = {40},
number = {2},
pages = {136-157},
year = {2015},
doi = {10.3102/1076998615570945},

URL = { 
        https://doi.org/10.3102/1076998615570945
    
},
eprint = { 
        https://doi.org/10.3102/1076998615570945
    
}
,
    abstract = { When fitting hierarchical regression models, maximum likelihood (ML) estimation has computational (and, for some users, philosophical) advantages compared to full Bayesian inference, but when the number of groups is small, estimates of the covariance matrix (Σ) of group-level varying coefficients are often degenerate. One can do better, even from a purely point estimation perspective, by using a prior distribution or penalty function. In this article, we use Bayes modal estimation to obtain positive definite covariance matrix estimates. We recommend a class of Wishart (not inverse-Wishart) priors for Σ with a default choice of hyperparameters, that is, the degrees of freedom are set equal to the number of varying coefficients plus 2, and the scale matrix is the identity matrix multiplied by a value that is large relative to the scale of the problem. This prior is equivalent to independent gamma priors for the eigenvalues of Σ with shape parameter 1.5 and rate parameter close to 0. It is also equivalent to independent gamma priors for the variances with the same hyperparameters multiplied by a function of the correlation coefficients. With this default prior, the posterior mode for Σ is always strictly positive definite. Furthermore, the resulting uncertainty for the fixed coefficients is less underestimated than under classical ML or restricted maximum likelihood estimation. We also suggest an extension of our method that can be used when stronger prior information is available for some of the variances or correlations. }
}
